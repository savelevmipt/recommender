{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 20:42:07.736145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.6 (default, Mar 10 2023, 20:16:38) \n",
      "[Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "Tensorflow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets.amazon_reviews import get_review_data\n",
    "from recommenders.datasets.split_utils import filter_k_core\n",
    "\n",
    "# Transformer Based Models\n",
    "from recommenders.models.sasrec.model import SASREC\n",
    "from recommenders.models.sasrec.ssept import SSEPT\n",
    "\n",
    "# Sampler for sequential prediction\n",
    "from recommenders.models.sasrec.sampler import WarpSampler\n",
    "from recommenders.models.sasrec.util import SASRecDataSet\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "RANDOM_SEED = 100  # Set None for non-deterministic result\n",
    "\n",
    "# data_dir = os.path.join(\"tests\", \"recsys_data\", \"RecSys\", \"SASRec-tf2\", \"data\")\n",
    "data_dir = os.path.join(\"..\", \"..\", \"tests\", \"resources\", \"deeprec\", \"sasrec\")\n",
    "\n",
    "# Amazon Electronics Data\n",
    "dataset = \"reviews_Electronics_5\"\n",
    "\n",
    "lr = 0.001             # learning rate\n",
    "maxlen = 50            # maximum sequence length for each user\n",
    "num_blocks = 2         # number of transformer blocks\n",
    "hidden_units = 100     # number of units in the attention calculation\n",
    "num_heads = 1          # number of attention heads\n",
    "dropout_rate = 0.1     # dropout rate\n",
    "l2_emb = 0.0           # L2 regularization coefficient\n",
    "num_neg_test = 100     # number of negative examples per positive example\n",
    "model_name = 'ssept'  # 'sasrec' or 'ssept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 484k/484k [11:52<00:00, 680KB/s]    \n"
     ]
    }
   ],
   "source": [
    "reviews_name = dataset + '.json'\n",
    "outfile = dataset + '.txt'\n",
    "\n",
    "reviews_file = os.path.join(data_dir, reviews_name)\n",
    "if not os.path.exists(reviews_file):\n",
    "    reviews_output = get_review_data(reviews_file)\n",
    "else:\n",
    "    reviews_output = os.path.join(data_dir, dataset+\".json_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(data_dir, outfile)):\n",
    "    df = pd.read_csv(reviews_output, sep=\"\\t\", names=[\"userID\", \"itemID\", \"time\"])\n",
    "    df = filter_k_core(df, 10)  # filter for users & items with less than 10 interactions\n",
    "    \n",
    "    user_set, item_set = set(df['userID'].unique()), set(df['itemID'].unique())\n",
    "    user_map = dict()\n",
    "    item_map = dict()\n",
    "    for u, user in enumerate(user_set):\n",
    "        user_map[user] = u+1\n",
    "    for i, item in enumerate(item_set):\n",
    "        item_map[item] = i+1\n",
    "    \n",
    "    df[\"userID\"] = df[\"userID\"].apply(lambda x: user_map[x])\n",
    "    df[\"itemID\"] = df[\"itemID\"].apply(lambda x: item_map[x])\n",
    "    df = df.sort_values(by=[\"userID\", \"time\"])\n",
    "    df.drop(columns=[\"time\"], inplace=True)\n",
    "    df.to_csv(os.path.join(data_dir, outfile), sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../tests/resources/deeprec/sasrec/reviews_Electronics_5.txt\n",
      "20247 Users and 11589 items\n",
      "average sequence length: 15.16\n"
     ]
    }
   ],
   "source": [
    "inp_file = os.path.join(data_dir, dataset + \".txt\")\n",
    "print(inp_file)\n",
    "\n",
    "# initiate a dataset class \n",
    "data = SASRecDataSet(filename=inp_file, col_sep=\"\\t\")\n",
    "\n",
    "# create train, validation and test splits\n",
    "data.split()\n",
    "\n",
    "# some statistics\n",
    "num_steps = int(len(data.user_train) / batch_size)\n",
    "cc = 0.0\n",
    "for u in data.user_train:\n",
    "    cc += len(data.user_train[u])\n",
    "print('%g Users and %g items' % (data.usernum, data.itemnum))\n",
    "print('average sequence length: %.2f' % (cc / len(data.user_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'sasrec':\n",
    "    model = SASREC(item_num=data.itemnum,\n",
    "                   seq_max_len=maxlen,\n",
    "                   num_blocks=num_blocks,\n",
    "                   embedding_dim=hidden_units,\n",
    "                   attention_dim=hidden_units,\n",
    "                   attention_num_heads=num_heads,\n",
    "                   dropout_rate=dropout_rate,\n",
    "                   conv_dims = [100, 100],\n",
    "                   l2_reg=l2_emb,\n",
    "                   num_neg_test=num_neg_test\n",
    "    )\n",
    "elif model_name == \"ssept\":\n",
    "    model = SSEPT(item_num=data.itemnum,\n",
    "                  user_num=data.usernum,\n",
    "                  seq_max_len=maxlen,\n",
    "                  num_blocks=num_blocks,\n",
    "                  # embedding_dim=hidden_units,  # optional\n",
    "                  user_embedding_dim=10,\n",
    "                  item_embedding_dim=hidden_units,\n",
    "                  attention_dim=hidden_units,\n",
    "                  attention_num_heads=num_heads,\n",
    "                  dropout_rate=dropout_rate,\n",
    "                  conv_dims = [110, 110],\n",
    "                  l2_reg=l2_emb,\n",
    "                  num_neg_test=num_neg_test\n",
    "    )\n",
    "else:\n",
    "    print(f\"Model-{model_name} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WarpSampler(data.user_train, data.usernum, data.itemnum, batch_size=batch_size, maxlen=maxlen, n_workers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5, test (NDCG@10: 0.31477525002553514, HR@10: 0.5235)\n",
      "Time cost for training is 10.18 mins\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    t_test = model.train(data, sampler, num_epochs=num_epochs, batch_size=batch_size, lr=lr, val_epoch=6)\n",
    "\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ndcg@10': 0.31477525002553514, 'Hit@10': 0.5235}\n"
     ]
    }
   ],
   "source": [
    "res_syn = {\"ndcg@10\": t_test[0], \"Hit@10\": t_test[1]}\n",
    "print(res_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.31477525002553514,
       "encoder": "json",
       "name": "ndcg@10",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "ndcg@10"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.5235,
       "encoder": "json",
       "name": "Hit@10",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "Hit@10"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Record results with papermill for tests - ignore this cell\n",
    "# sb.glue(\"res_syn\", res_syn)\n",
    "\n",
    "sb.glue(\"ndcg@10\", t_test[0])\n",
    "sb.glue(\"Hit@10\", t_test[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
